{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random\n",
    "from tensorflow.contrib.learn.python.learn.datasets.mnist import read_data_sets\n",
    "from tensorflow.python.framework import ops\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Restore trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from D:/Eun/CNN4PM/savedModel/training_model.ckpt-499\n",
      "Extracting temp\\train-images-idx3-ubyte.gz\n",
      "Extracting temp\\train-labels-idx1-ubyte.gz\n",
      "Extracting temp\\t10k-images-idx3-ubyte.gz\n",
      "Extracting temp\\t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# Start a graph session\n",
    "sess = tf.Session()\n",
    "\n",
    "saver = tf.train.import_meta_graph('D:/Eun/CNN4PM/savedModel/training_model.ckpt-499.meta')\n",
    "saver.restore(sess,tf.train.latest_checkpoint('D:/Eun/CNN4PM/savedModel'))\n",
    "\n",
    "\n",
    "# Load data\n",
    "data_dir = 'temp'\n",
    "mnist = read_data_sets(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert images into 28x28 (they are downloaded as 1x784)\n",
    "test_xdata = np.array([np.reshape(x, (28,28)) for x in mnist.test.images])\n",
    "\n",
    "# Convert labels into one-hot encoded vectors\n",
    "test_labels = mnist.test.labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set model parameters\n",
    "batch_size = 100\n",
    "learning_rate = 0.005\n",
    "image_width = test_xdata[0].shape[0]\n",
    "image_height = test_xdata[0].shape[1]\n",
    "num_channels = 1 # greyscale = 1 channel\n",
    "generations = 500\n",
    "eval_every = 5\n",
    "conv1_features = 25\n",
    "conv2_features = 50\n",
    "max_pool_size1 = 2 # NxN window for 1st max pool layer\n",
    "max_pool_size2 = 2 # NxN window for 2nd max pool layer\n",
    "fully_connected_size1 = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare model placeholders\n",
    "x_input_shape = (batch_size, image_width, image_height, num_channels)\n",
    "x_input = tf.placeholder(tf.float32, shape=x_input_shape)\n",
    "y_target = tf.placeholder(tf.int32, shape=(batch_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get variables from trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Restore model parameters\n",
    "graph = tf.get_default_graph()\n",
    "\n",
    "conv1_weight = graph.get_tensor_by_name(\"conv1_weight:0\")\n",
    "conv1_bias = graph.get_tensor_by_name(\"conv1_bias:0\")\n",
    "\n",
    "conv2_weight = graph.get_tensor_by_name(\"conv2_weight:0\")\n",
    "conv2_bias = graph.get_tensor_by_name(\"conv2_bias:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fully connected variables\n",
    "resulting_width = image_width // (max_pool_size1 * max_pool_size2)\n",
    "resulting_height = image_height // (max_pool_size1 * max_pool_size2)\n",
    "full1_input_size = resulting_width * resulting_height * conv2_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "full1_weight = graph.get_tensor_by_name(\"full1_weight:0\")\n",
    "full1_bias = graph.get_tensor_by_name(\"full1_bias:0\")\n",
    "full2_weight = graph.get_tensor_by_name(\"full2_weight:0\")\n",
    "full2_bias = graph.get_tensor_by_name(\"full2_bias:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Model Operations\n",
    "def my_conv_net(input_data):\n",
    "    # First Conv-ReLU-MaxPool Layer\n",
    "    conv1 = tf.nn.conv2d(input_data, conv1_weight, strides=[1, 1, 1, 1], padding='SAME',)\n",
    "    relu1 = tf.nn.relu(tf.nn.bias_add(conv1, conv1_bias))\n",
    "    max_pool1 = tf.nn.max_pool(relu1, ksize=[1, max_pool_size1, max_pool_size1, 1],\n",
    "                               strides=[1, max_pool_size1, max_pool_size1, 1], padding='SAME')\n",
    "\n",
    "    # Second Conv-ReLU-MaxPool Layer\n",
    "    conv2 = tf.nn.conv2d(max_pool1, conv2_weight, strides=[1, 1, 1, 1], padding='SAME')\n",
    "    relu2 = tf.nn.relu(tf.nn.bias_add(conv2, conv2_bias))\n",
    "    max_pool2 = tf.nn.max_pool(relu2, ksize=[1, max_pool_size2, max_pool_size2, 1],\n",
    "                               strides=[1, max_pool_size2, max_pool_size2, 1], padding='SAME')\n",
    "\n",
    "    # Transform Output into a 1xN layer for next fully connected layer\n",
    "    final_conv_shape = max_pool2.get_shape().as_list()\n",
    "    final_shape = final_conv_shape[1] * final_conv_shape[2] * final_conv_shape[3]\n",
    "    flat_output = tf.reshape(max_pool2, [final_conv_shape[0], final_shape])\n",
    "\n",
    "    # First Fully Connected Layer\n",
    "    fully_connected1 = tf.nn.relu(tf.add(tf.matmul(flat_output, full1_weight), full1_bias))\n",
    "\n",
    "    # Second Fully Connected Layer\n",
    "    final_model_output = tf.add(tf.matmul(fully_connected1, full2_weight), full2_bias,  name=\"operation_restore\")\n",
    "    \n",
    "    return(final_model_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_output = my_conv_net(x_input)                # training\n",
    "\n",
    "# Create a prediction function\n",
    "prediction = tf.nn.softmax(model_output,name = 'prediction')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feed placeholder and run graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = sess.run(prediction, feed_dict={x_input: np.reshape(test_xdata[:100],[100,28,28,1])})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAEICAYAAACQ6CLfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngwl7QAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1d57b663f28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "num=random.randrange(0,100)\n",
    "plt.imshow(test_xdata[num])\n",
    "plt.title('Actual: ' + str(test_labels[num]) + ' Pred: ' + str(np.argmax(result[num], axis=0)))\n",
    "plt.show()\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
