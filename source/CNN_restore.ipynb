{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random\n",
    "from tensorflow.contrib.learn.python.learn.datasets.mnist import read_data_sets\n",
    "from tensorflow.python.framework import ops\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Restore trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from D:/Eun/CNN4PM/savedModel/1_CNN4PM.ckpt-499\n",
      "Extracting temp\\train-images-idx3-ubyte.gz\n",
      "Extracting temp\\train-labels-idx1-ubyte.gz\n",
      "Extracting temp\\t10k-images-idx3-ubyte.gz\n",
      "Extracting temp\\t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# Start a graph session\n",
    "sess = tf.Session()\n",
    "\n",
    "saver = tf.train.import_meta_graph('D:/Eun/CNN4PM/savedModel/training_model.ckpt-499.meta')\n",
    "saver.restore(sess,tf.train.latest_checkpoint('D:/Eun/CNN4PM/savedModel'))\n",
    "\n",
    "\n",
    "# Load data\n",
    "data_dir = 'temp'\n",
    "mnist = read_data_sets(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert images into 28x28 (they are downloaded as 1x784)\n",
    "test_xdata = np.array([np.reshape(x, (28,28)) for x in mnist.test.images])\n",
    "\n",
    "# Convert labels into one-hot encoded vectors\n",
    "test_labels = mnist.test.labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set model parameters\n",
    "batch_size = 100\n",
    "learning_rate = 0.005\n",
    "image_width = test_xdata[0].shape[0]\n",
    "image_height = test_xdata[0].shape[1]\n",
    "num_channels = 1 # greyscale = 1 channel\n",
    "generations = 500\n",
    "eval_every = 5\n",
    "conv1_features = 25\n",
    "conv2_features = 50\n",
    "max_pool_size1 = 2 # NxN window for 1st max pool layer\n",
    "max_pool_size2 = 2 # NxN window for 2nd max pool layer\n",
    "fully_connected_size1 = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare model placeholders\n",
    "x_input_shape = (batch_size, image_width, image_height, num_channels)\n",
    "x_input = tf.placeholder(tf.float32, shape=x_input_shape)\n",
    "y_target = tf.placeholder(tf.int32, shape=(batch_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get variables from trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Restore model parameters\n",
    "graph = tf.get_default_graph()\n",
    "\n",
    "conv1_weight = graph.get_tensor_by_name(\"conv1_weight:0\")\n",
    "conv1_bias = graph.get_tensor_by_name(\"conv1_bias:0\")\n",
    "\n",
    "conv2_weight = graph.get_tensor_by_name(\"conv2_weight:0\")\n",
    "conv2_bias = graph.get_tensor_by_name(\"conv2_bias:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fully connected variables\n",
    "resulting_width = image_width // (max_pool_size1 * max_pool_size2)\n",
    "resulting_height = image_height // (max_pool_size1 * max_pool_size2)\n",
    "full1_input_size = resulting_width * resulting_height * conv2_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "full1_weight = graph.get_tensor_by_name(\"full1_weight:0\")\n",
    "full1_bias = graph.get_tensor_by_name(\"full1_bias:0\")\n",
    "full2_weight = graph.get_tensor_by_name(\"full2_weight:0\")\n",
    "full2_bias = graph.get_tensor_by_name(\"full2_bias:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Model Operations\n",
    "def my_conv_net(input_data):\n",
    "    # First Conv-ReLU-MaxPool Layer\n",
    "    conv1 = tf.nn.conv2d(input_data, conv1_weight, strides=[1, 1, 1, 1], padding='SAME',)\n",
    "    relu1 = tf.nn.relu(tf.nn.bias_add(conv1, conv1_bias))\n",
    "    max_pool1 = tf.nn.max_pool(relu1, ksize=[1, max_pool_size1, max_pool_size1, 1],\n",
    "                               strides=[1, max_pool_size1, max_pool_size1, 1], padding='SAME')\n",
    "\n",
    "    # Second Conv-ReLU-MaxPool Layer\n",
    "    conv2 = tf.nn.conv2d(max_pool1, conv2_weight, strides=[1, 1, 1, 1], padding='SAME')\n",
    "    relu2 = tf.nn.relu(tf.nn.bias_add(conv2, conv2_bias))\n",
    "    max_pool2 = tf.nn.max_pool(relu2, ksize=[1, max_pool_size2, max_pool_size2, 1],\n",
    "                               strides=[1, max_pool_size2, max_pool_size2, 1], padding='SAME')\n",
    "\n",
    "    # Transform Output into a 1xN layer for next fully connected layer\n",
    "    final_conv_shape = max_pool2.get_shape().as_list()\n",
    "    final_shape = final_conv_shape[1] * final_conv_shape[2] * final_conv_shape[3]\n",
    "    flat_output = tf.reshape(max_pool2, [final_conv_shape[0], final_shape])\n",
    "\n",
    "    # First Fully Connected Layer\n",
    "    fully_connected1 = tf.nn.relu(tf.add(tf.matmul(flat_output, full1_weight), full1_bias))\n",
    "\n",
    "    # Second Fully Connected Layer\n",
    "    final_model_output = tf.add(tf.matmul(fully_connected1, full2_weight), full2_bias,  name=\"operation_restore\")\n",
    "    \n",
    "    return(final_model_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_output = my_conv_net(x_input)                # training\n",
    "\n",
    "# Create a prediction function\n",
    "prediction = tf.nn.softmax(model_output,name = 'prediction')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feed placeholder and run graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = sess.run(prediction, feed_dict={x_input: np.reshape(test_xdata[:100],[100,28,28,1])})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAEICAYAAACQ6CLfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ns0Q5/GaJcvjNEvV/KGAq4p1+uNIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1e1701cab38>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num=random.randrange(0,100)\n",
    "plt.imshow(test_xdata[num])\n",
    "plt.title('Actual: ' + str(test_labels[num]) + ' Pred: ' + str(np.argmax(result[num], axis=0)))\n",
    "plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
